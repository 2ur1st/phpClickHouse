{
  "name": "phpClickhouse",
  "tagline": "php ClickHouse wrapper|driver",
  "body": "php ClickHouse wrapper\r\n===================\r\n\r\n\r\n##Features\r\n\r\n* No dependency, only curl \r\n* Select parallel queries (asynchronous)\r\n* Parallelizing bulk inserts from CSV file\r\n* enable_http_compression, for bulk inserts \r\n* Find active host and check cluster\r\n* Select WHERE IN ( _local csv file_ )\r\n* SQL conditions & template\r\n* tablesSize & databaseSize\r\n* listPartitions\r\n* pre production :  dropPartition & dropOldPartitions \r\n* Insert array as column\r\n\r\n\r\n## Install \r\n\r\n```\r\ncomposer require smi2/phpclickhouse\r\n```\r\n\r\n\r\npackagist : https://packagist.org/packages/smi2/phpclickhouse\r\n\r\n## Start\r\n\r\nConnect and select database:\r\n```php\r\n$config = [\r\n    'host' => '192.168.1.1', \r\n    'port' => '8123', \r\n    'username' => 'default', \r\n    'password' => ''\r\n];\r\n$db = new ClickHouseDB\\Client($config);\r\n$db->database('default');\r\n```\r\n\r\nShow tables:\r\n```php\r\nprint_r($db->showTables());\r\n```\r\n\r\nCreate table:\r\n```php\r\n$db->write('\r\n    CREATE TABLE IF NOT EXISTS summing_url_views (\r\n        event_date Date DEFAULT toDate(event_time),\r\n        event_time DateTime,\r\n        site_id Int32,\r\n        site_key String,\r\n        views Int32,\r\n        v_00 Int32,\r\n        v_55 Int32\r\n    ) \r\n    ENGINE = SummingMergeTree(event_date, (site_id, site_key, event_time, event_date), 8192)\r\n';\r\n```\r\nShow create table:\r\n```php\r\necho $db->showCreateTable('summing_url_views');\r\n```\r\nInsert data:\r\n```php\r\n$stat = $db->insert('summing_url_views', \r\n    [\r\n        [time(), 'HASH1', 2345, 22, 20, 2],\r\n        [time(), 'HASH2', 2345, 12, 9,  3],\r\n        [time(), 'HASH3', 5345, 33, 33, 0],\r\n        [time(), 'HASH3', 5345, 55, 0, 55],\r\n    ],\r\n    ['event_time', 'site_key', 'site_id', 'views', 'v_00', 'v_55']\r\n);\r\n```\r\n\r\nSelect:\r\n```php\r\n$statement = $db->select('SELECT * FROM summing_url_views LIMIT 2');\r\n```\r\n\r\nWork with Statement:\r\n```php\r\n// Count select rows\r\n$statement->count();\r\n\r\n// Count all rows\r\n$statement->countAll();\r\n\r\n// fetch one row\r\n$statement->fetchOne();\r\n\r\n// get extremes min\r\nprint_r($statement->extremesMin());\r\n\r\n// totals row\r\nprint_r($statement->totals());\r\n\r\n// result all\r\nprint_r($statement->rows());\r\n\r\n// totalTimeRequest\r\nprint_r($statement->totalTimeRequest());\r\n\r\n// raw answer JsonDecode array, for economy memory\r\nprint_r($statement->rawData());\r\n\r\n// raw curl_info answer \r\nprint_r($statement->responseInfo());\r\n\r\n// human size info\r\nprint_r($statement->info());\r\n\r\n// if clickhouse-server version >= 54011\r\n$db->settings()->set('output_format_write_statistics',true);\r\nprint_r($result->statistics());\r\n```\r\n\r\nSelect result as tree:\r\n```php\r\n$statement = $db->select('\r\n    SELECT event_date, site_key, sum(views), avg(views) \r\n    FROM summing_url_views \r\n    WHERE site_id < 3333 \r\n    GROUP BY event_date, url_hash \r\n    WITH TOTALS\r\n');\r\n\r\nprint_r($statement->rowsAsTree('event_date.site_key'));\r\n\r\n/*\r\n(\r\n    [2016-07-18] => Array\r\n        (\r\n            [HASH2] => Array\r\n                (\r\n                    [event_date] => 2016-07-18\r\n                    [url_hash] => HASH2\r\n                    [sum(views)] => 12\r\n                    [avg(views)] => 12\r\n                )\r\n            [HASH1] => Array\r\n                (\r\n                    [event_date] => 2016-07-18\r\n                    [url_hash] => HASH1\r\n                    [sum(views)] => 22\r\n                    [avg(views)] => 22\r\n                )\r\n        )\r\n)\r\n*/\r\n```\r\nDrop table:\r\n```php\r\n$db->write('DROP TABLE IF EXISTS summing_url_views');\r\n```\r\n\r\n\r\nFeatures\r\n----\r\n### Select parallel queries (asynchronous)\r\n```php\r\n$state1 = $db->selectAsync('SELECT 1 as ping');\r\n$state2 = $db->selectAsync('SELECT 2 as ping');\r\n\r\n// run\r\n$db->executeAsync();\r\n\r\n// result\r\nprint_r($state1->rows());\r\nprint_r($state2->fetchOne('ping'));\r\n```\r\n\r\n### Parallelizing massive inserts from CSV file\r\n```php\r\n$file_data_names = [\r\n    '/tmp/clickHouseDB_test.1.data',\r\n    '/tmp/clickHouseDB_test.2.data',\r\n    '/tmp/clickHouseDB_test.3.data',\r\n    '/tmp/clickHouseDB_test.4.data',\r\n    '/tmp/clickHouseDB_test.5.data',\r\n];\r\n\r\n// insert all files\r\n$stat = $db->insertBatchFiles(\r\n    'summing_url_views',\r\n    $file_data_names,\r\n    ['event_time', 'site_key', 'site_id', 'views', 'v_00', 'v_55']\r\n);\r\n```\r\n### Parallelizing errors\r\n\r\nselectAsync without executeAsync\r\n\r\n```php\r\n$select = $db->selectAsync('SELECT * FROM summing_url_views LIMIT 1');\r\n$insert = $db->insertBatchFiles('summing_url_views', ['/tmp/clickHouseDB_test.1.data'], ['event_time']);\r\n// 'Exception' with message 'Queue must be empty, before insertBatch, need executeAsync'\r\n```\r\nsee example/exam5_error_async.php\r\n\r\n### Gzip & enable_http_compression\r\n\r\nOn fly read CSV file and compress zlib.deflate.\r\n  \r\n\r\n```php\r\n$db->settings()->max_execution_time(200);\r\n$db->enableHttpCompression(true);\r\n\r\n$result_insert = $db->insertBatchFiles('summing_url_views', $file_data_names, [...]);\r\n\r\n\r\nforeach ($result_insert as $fileName => $state) {\r\n    echo $fileName . ' => ' . json_encode($state->info_upload()) . PHP_EOL;\r\n}\r\n```\r\nsee example/exam8_http_gzip_batch_insert.php\r\n\r\n\r\n\r\n\r\n### tablesSize & databaseSize\r\n\r\nResult in _human size_\r\n\r\n```php\r\nprint_r($db->databaseSize());\r\nprint_r($db->tablesSize());\r\nprint_r($db->tableSize('summing_partions_views'));\r\n```\r\n\r\n\r\n### Partitions\r\n\r\n```php\r\n$count_result = 2;\r\nprint_r($db->partitions('summing_partions_views', $count_result));\r\n```\r\n\r\nDrop partitions ( pre production )\r\n\r\n```php\r\n$count_old_days = 10;\r\nprint_r($db->dropOldPartitions('summing_partions_views', $count_old_days));\r\n\r\n// by `partition_id` \r\nprint_r($db->dropPartition('summing_partions_views', '201512'));\r\n```\r\n\r\n\r\n\r\n### Select WHERE IN ( _local csv file_ )\r\n```php\r\n$file_name_data1 = '/tmp/temp_csv.txt'; // two column file [int,string]\r\n$whereIn = new \\ClickHouseDB\\WhereInFile();\r\n$whereIn->attachFile($file_name_data1, 'namex', ['site_id' => 'Int32', 'site_hash' => 'String'], \\ClickHouseDB\\WhereInFile::FORMAT_CSV);\r\n$result = $db->select($sql, [], $whereIn);\r\n\r\n// see example/exam7_where_in.php\r\n```\r\n\r\n\r\n\r\n### Simple sql conditions & template\r\n\r\nconditions is depricated, if need use: \r\n`$db->enableQueryConditions();`\r\n\r\n\r\nExample with QueryConditions:\r\n\r\n```php\r\n\r\n$db->enableQueryConditions();\r\n\r\n$input_params = [\r\n  'select_date' => ['2000-10-10', '2000-10-11', '2000-10-12'],\r\n  'limit' => 5,\r\n  'from_table' => 'table'\r\n];\r\n\r\n$select = '\r\n    SELECT * FROM {from_table}\r\n    WHERE\r\n    {if select_date}\r\n        event_date IN (:select_date)\r\n    {else}\r\n        event_date=today()\r\n    {/if}\r\n    {if limit}\r\n    LIMIT {limit}\r\n    {/if}\r\n';\r\n\r\n$statement = $db->selectAsync($select, $input_params);\r\necho $statement->sql();\r\n\r\n/*\r\nSELECT * FROM table\r\nWHERE\r\nevent_date IN ('2000-10-10','2000-10-11','2000-10-12')\r\nLIMIT 5\r\nFORMAT JSON\r\n*/\r\n\r\n\r\n$input_params['select_date'] = false;\r\n$statement = $db->selectAsync($select, $input_params);\r\necho $statement->sql();\r\n\r\n/*\r\nSELECT * FROM table\r\nWHERE\r\nevent_date=today()\r\nLIMIT 5\r\nFORMAT JSON\r\n*/\r\n\r\n\r\n$state1 = $db->selectAsync(\r\n    'SELECT 1 as {key} WHERE {key} = :value', \r\n    ['key' => 'ping', 'value' => 1]\r\n);\r\n\r\n// SELECT 1 as ping WHERE ping = \"1\"\r\n```\r\n\r\n\r\nExample custom query Degeneration in `exam16_custom_degeneration.php`\r\n\r\n### Settings\r\n\r\n3 way set any settings\r\n```php\r\n// in array config\r\n$config = [\r\n    'host' => 'x', \r\n    'port' => '8123', \r\n    'username' => 'x', \r\n    'password' => 'x', \r\n    'settings' => ['max_execution_time' => 100]\r\n];\r\n$db = new ClickHouseDB\\Client($config);\r\n\r\n// settings via constructor \r\n$config = [\r\n    'host' => 'x', \r\n    'port' => '8123', \r\n    'username' => 'x', \r\n    'password' => 'x'\r\n];\r\n$db = new ClickHouseDB\\Client($config, ['max_execution_time' => 100]);\r\n\r\n// set method\r\n$config = [\r\n    'host' => 'x', \r\n    'port' => '8123',\r\n    'username' => 'x',\r\n    'password' => 'x'\r\n];\r\n$db = new ClickHouseDB\\Client($config);\r\n$db->settings()->set('max_execution_time', 100);\r\n\r\n// apply array method \r\n$db->settings()->apply([\r\n    'max_execution_time' => 100,\r\n    'max_block_size' => 12345\r\n]);\r\n\r\n\r\n// check\r\nif ($db->settings()->getSetting('max_execution_time') !== 100) {\r\n    throw new Exception('Bad work settings');\r\n}\r\n\r\n// see example/exam10_settings.php\r\n```\r\n### Array as column\r\n\r\n```php\r\n\r\n$db->write('\r\n    CREATE TABLE IF NOT EXISTS arrays_test_string (\r\n        s_key String,\r\n        s_arr Array(String)\r\n    ) \r\n    ENGINE = Memory\r\n');\r\n\r\n$db->insert('arrays_test_string',\r\n    [\r\n        ['HASH1', [\"a\", \"dddd\", \"xxx\"]],\r\n        ['HASH1', [\"b'\\tx\"]],\r\n    ],\r\n    ['s_key', 's_arr']\r\n);\r\n\r\n// see example/exam12_array.php\r\n```\r\n\r\nClass for CSV array\r\n```php\r\nvar_dump(\r\n    \\ClickHouseDB\\CSV::quoteRow(\r\n        ['HASH1', [\"a\", \"dddd\", \"xxx\"]]\r\n    )\r\n);\r\n```\r\n\r\n### Phpunit Test\r\n\r\n\r\nIn phpunit.xml change constants:\r\n```xml\r\n<php>\r\n    <const name=\"phpunit_clickhouse_host\" value=\"192.168.1.20\" />\r\n    <const name=\"phpunit_clickhouse_port\" value=\"8123\" />\r\n    <const name=\"phpunit_clickhouse_user\" value=\"default\" />\r\n    <const name=\"phpunit_clickhouse_pass\" value=\"\" />\r\n    <const name=\"phpunit_clickhouse_tmp_path\" value=\"/tmp/\" />\r\n</php>\r\n```\r\n \r\n \r\nLicense\r\n----\r\n\r\nMIT\r\n\r\nChangeLog\r\n---\r\n###  2016-09-20 Release 0.16.09 \r\n\r\n- Version/Release names: [ zero dot year dot month]\r\n- Support cluster: new class Cluster and ClusterQuery\r\n- output_format_write_statistics, for clickhouse version > v1.1.54019-stable \r\n- WriteToFile in select,selectAsync\r\n- Degeneration for Bindings & Conditions\r\n- $db->select(new Query(\"Select...\"));\r\n- remove findActiveHostAndCheckCluster , clusterHosts , checkServerReplicas\r\n- Add cleanQueryDegeneration(),addQueryDegeneration()\r\n- Need $db->enableQueryConditions(); for use Conditions ; default Conditions - disabled;\r\n- float in CurlerRequest->timeOut(2.5) = 2500 ms\r\n- tablesSize() - add `sizebytes`\r\n\r\n\r\n\r\n\r\n### 2016-08-11 Release 0.2.0  \r\n- exception on error write \r\n\r\n### 2016-08-06 Release 0.1.0 \r\n- init",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}