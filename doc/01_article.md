Запускаем ClickHouse своими силами и радуемся скорости и аналитическим возможностям
В статье описан простой и проверенный путь для тех, кто хочет внедрить аналитическую СУБД ClickHouse своими силами или просто опробовать ClickHouse на собственных данных. Именно этот путь мы прошли сами, в компании СМИ2.


В предисловии статьи — небольшой рассказ о наших попытках внедрить Druid и InfluxDB. Почему после успешного запуска ClickHouse мы смогли отказаться от использования InfiniDB и Cassandra. Основная часть статьи посвящена продуктам-помощникам для работы с ClickHouse, которые мы сами разработали и выпустили в open-source. Кстати, добро пожаловать в pull requests с предложениями и замечаниями.


Предполагаем, что читатель знаком с официальной документацией ClickHouse.
Кто мы такие и с какими данными работаем
В начале — о том, кто мы такие и с какими данными работаем. На примере одного из набора наших данных мы и будем далее разбирать работу с ClickHouse.


СМИ2 —  информационный сервис, который с 2007 года круглосуточно поставляет актуальные новости и формирует полноценную информационную картину дня. На сегодняшний день СМИ2 включает в себя новостной агрегатор и партнёрскую сеть с более чем 2500 участников, среди которых: ресурсы федерального уровня, отраслевые сайты и региональные издания. Месячная аудитория СМИ2 составляет порядка 15 млн человек.


Мы будем разбираться работу с ClickHouse на примере данных, собирамых с нашего новостного агрегатора, который представлен тремя региональными сайтами: smi2.ru, smi2.ua и smi2.kz. На каждом сайте мы собираем и обрабатываем данные о просмотрах и кликах по новостям. Эти данные используются как в режиме реального времени — для выдачи контента, так и для постанализа эффективности материалов.


В вашем случае анализируемыми данными могут быть, например: логи сервера, статистика по событиям на сайтах, в системах бронирования, электронной рассылки, отслеживания показаний датчиков и т. п. Во всех этих случаях ClickHouse стоит того, чтобы попробовать.
Как мы пришли к ClickHouse
Мы определили для себя следующие критические требования к аналитической СУБД:
скорость обработки запросов в режиме реального времени
наличие встроенных аналитических функций,
наличие функций для приближённых вычислений,
линейная масштабируемость, т. к. добиться линейной масштабируемости без деградации с ростом числа серверов — сложнейшая техническая задача
наличие механизмов шардирования и репликации данных «из коробки»
отсутствие единой точки отказа; в каждый узел в кластере можно писать данные


В качестве предыстории хотелось бы рассказать о том, какой технологический стек мы использовали ранее, от чего пришлось отказаться, и как мы пришли к ClickHouse.
Неудачный опыт с Druid и InfluxDB
В этом году (так?) мы развернули druid.io, сборку на основе Druid : Imply Analytics Platform, и уже приготовились запускать в продакшн, но…




Ссылки: 
http://druid.io/ 
https://imply.io/product
https://github.com/druid-io/tranquility




Из плюсов отметили для себя следующее:
Поддержка RT stream из HTTP, Spark, Kafka и т. д.
Графические инструменты Pivot, Caravel 


Однако следующие недостатки перевесили чашу весов, и мы, в итоге, отказались от запуска Druid:
Сложность инфраструктуры: требуются отдельные ноды для получения, обработки и хранения данных, для отказоустойчивости держать по 2x нод 
Tranquility, предназначенный для realtime обработки данных, содержит ошибки приводящие к падению всего Tranquility; версии Tranquility —  не совместимы между собой; Оцениваем состояние Tranquility как Beta версия, хороший интересный продукт но пока в состоянии Beta   


Также у нас был пробный подход к InfluxDB http://influxdata.com/ + https://habrahabr.ru/company/selectel/blog/245515/, которую мы планировали использовать для построения и анализа метрик. Проект мы оценили для себя как глубокую Alfa из-за частых потерь данных и падений системы, поэтому это направление мы тоже решили свернуть. Возможно сейчас состояние продукта изменилось в лучшую сторону.
Cassandra и InfiniDB продержались у нас два года
Cassandra использовалась у нас в продакшне с 2014 по 2016 год:  
Работала на 5 серверах
Выдерживала нагрузку до 10К событий в секунду на вставку и примерно до 1К событий в секунду на чтение
Примерно 1 раз в 2 месяца случались рассинхронизации схем данных


В этот же период мы использовали и InfiniDB https://github.com/infinidb/infinidb . Из положительных моментов хотелось бы отметить такие:
Поддержка оконных функций   
Простота интеграции с существующим MySQL через движок Federated
Встроенный движок MyISAM и InnoDB, что позволяет делать выгрузки из движка InfiniDB в движок InnoDB внутри одного сервера 
Возможность удаление партиций данных по каждому дню, по определенным колонкам


Однако не обошлось и без негативных моментов:
Отсутствие нормального кластера и репликации данных. Приходилось делать горячую копию данных, т. е. клон сервера
Первые версии приходилось регулярно перегружать из-за утечек памяти и зависаний сервиса
Зависания процессов на запись или запросов на чтение. Пришлось убивать долгие процессы через event handlers nagios
Сложность загрузки данных. Есть только отдельный консольный инструмент cpimport. Пришлось реализовывать обёртку, которая разбирает STDOut на  ошибки и статистику результата выполнения вставки
Условная однопоточность: или пишем, или читаем. Потребляется большой объём системных ресурсов
И тут «Яндекс» выложил в открытый доступ ClickHouse 
В общем, недостатков и проблем с используемыми у нас для аналитики СУБД было достаточно. Поэтому мы регулярно смотрели по сторонам в поисках альтернатив. В том числе, мы обратили внимание на внутреннюю разработку «Яндекса», которая подкупала своей невероятной скорострельностью и в целом соответствовала нашим ожиданиям от аналитической СУБД (см. выше).


В настоящий момент на рынке нет аналитических баз данных дешевых или бесплатных для обработки больших данных в режиме реального времени уровня, подобного ClickHouse или мы не знаем об этом - доплнительно были тесты из платных это HP Vercia и greenplum . Аналитику можно считать и на MapReduce на Hadoop, но не в режиме близком реального времени. Кстати, в самом «Яндексе» есть YT («Ыть», как они сами её называют) — именно MapReduce-платформа для работы с большими данными, но она тоже не работает в режиме реального времени, хотя активно используется. То есть ClickHouse больше всего подходит для аналитики в режиме реального времени.


Поэтому, когда «Яндекс» опубликовал летом ClickHouse в открытом доступе, мы однозначно решили его попробовать.
Как нам помог ClickHouse
Можно однозначно утверждать, что процесс запуска ClickHouse прошёл у нас быстрее и проще, чем с другими СУБД. Надеемся, что наша статья позволит вам сделать это существенно быстрее :)


Если промотать историю о том, как мы запускали ClickHouse и, в итоге, успешно запустили, то стоит отметить следующие результаты запуска ClickHouse.


Выгоды в разработке.  В относительно короткий срок нам удалось закрыть 80 % задач, связанных с анализом данных, а этих задач накопилось много. Новые задачи по аналитике стали выполняться гораздо проще и быстрее.


Выгоды в железе. По сравнению с тем же Druid, требования к железу у ClickHouse оказались существенно ниже, поэтому нам удалось сэкономить на железе. Плюс мы отказались 5 нод под Cassandra, 4 нод под InfiniDB и 2 нод MySQL (исторически оставшейся аналитики). Итого мы отказались от 11 серверов за которыми нужно было постоянно присматривать и не пропускать алерты от nagios об их проблемах.


Выгоды в хранении данных. ClickHouse умеет хранить данные более компактно и размазано по нескольким сервера  в отличии от InfiniDB .


Выгоды в скорости. ClickHouse реально быстрый, мы убедились в этом на своих задачах, скорость возросла в несколько раз!


Здесь многие подумают, что неплохо было бы привести для примера бенчмарки… Предлагаем обратиться к бенчмаркам «Яндекса» и посмотреть наши ролики с запросами на реальных наборах данных.


Добавить видосы Игоря с краткими описания.


Статистика собираемых и анализируемых нами с помощью ClickHouse  данных на текущий момент такова:
Регистрируем до 8 000—12 000 событий в секунду
приблизительно 21,5 млрд событий за месяц
примерно 10 млрд строк в базе за месяц




Данные хранятся на 6ти серверах SX131 от Hetzner -  из которых  : три шарда и три это реплики, 
Особенности ClickHouse
Как у любого продукта для работы с данными, у ClickHouse есть свои особенности. Вот некоторые из них : 
Отсутствие UPDATE и производных: INSERT UPDATE и DELETE
Отсутствие транзакционности
Удаление данных по месяцу через удаление партиций


О них пишет сам «Яндекс» и в планах яндека добавить возможность удаление партиций по дням.


Кроме этого, ClickHouse не умеет строить графики «из коробки», для этого нужны дополнительные инструменты, хотя бы на уровне Pivot.


Для нас не принципиальна транзакционность, и UPDATE / Delete, мы давно привыклик обходить эти проблемы  - но очень хотелось бы иметь возмоность хранить данные только за несколько дней.
Наши проекты для ClickHouse
В процессе освоения и внедрения ClickHouse мы столкнулись с некоторыми неудобствами и отсутствием нужным нам «плюшек». Поэтому, не став ждать милостей от «Яндекса» природы, мы решили облегчить себе работу сами. Ещё одним мотиватором было то, что нам хотелось внести свой вклад в развитие молодого, но перспективного open-source проекта. Плюс — это был наш первый опыт участия в open-source разработке.


Так родились наши два open-source проекта, которые позволили нам самим существенно ускорить и упростить процесс внедрения ClickHouse и работу с ним: 
Графический клиент для работы с БД
Обёртка на PHP для удобной работы с БД, реализующая возможности ClickHouse


Ниже описаны основные возможности каждого проекта.
Наш графический клиент для ClickHouse: возможности и особенности
Просмотр списка баз данных и таблиц
Просмотр содержания таблицы


Подсветка функций ClickHouse, названий таблиц и полей 
Автодополнение для названий таблиц , колонок и встроенных функций
Выполнение выделенного / текущего / нескольких запросов в редакторе 
Автоматическое определение типа запроса: CREATE TABLE / INSERT / SELECT   
Удобная вставка словарей 
Темы для редактора запросов, тема оформления всего редактора светлая/темная 
Горячие клавиши


Клиент написал полностью на JavaScript, без использования server side.


Вы можете спокойно использовать наш последний опубликованный билд http://guiclickhouse.smi2.ru/.


https://monosnap.com/file/rIEnBkDoh0jMmhGDsu0umaqk5F0srt
Наш PHP-драйвер для ClickHouse: возможности и особенности
Отсутствие зависимостей, требуются только модули curl и json
Работа с кластером ClickHouse, автоматическое определение необходимых node при разных конфигурациях
Выполнение запроса на каждой node в кластере (см. наш отдельный проект, посвященный миграциям на ClickHouse)
Асинхронное выполнение запросов на чтение данных и вставку данных 
Поддержка сжатия на лету при записи данных в ClickHouse из локального файла, без создания временных файлов
Поддержка запросов на чтение с использованием локального CSV-файла, для выполнения запроса вида select * from X where id in (local_csv_file)
Работа с партициями таблиц
Вставка массива в колонку
Запись результата запроса напрямую в файл, с поддержкой сжатия без создания временных файлов
Получение размера таблицы, базы и списка процессов на каждой node
Получение статистики выполнения запроса SELECT


Драйвер протестирован на PHP 5.6 и 7, HHVM 3.9.


Оговорки: это нужно как то тут описать это важно засунуть под споллер - Оговорки : 
Cтоит сразу оговорится, драйвер не использует готовые решение в виде guzzle/PSR-7 и PSR-4: Autoloader реализован через файл include.php - надеюсь вас это не отпугнет от последующего прочтения      
Примеры работы с ClickHouse
Рассмотрим на примере наших данных, как работать ClickHouse из PHP и с помощью нашего графического клиента.


Считаем, что вы успешно установили ClickHouse из deb-пакета последней версии и ознакомились с Quick start guide https://clickhouse.yandex/tutorial.html.


Имеем список наших сайтов.


site_id
Домен
1
smi2.ru
2
smi2.ua
3
smi2.kz


На каждом сайте совершаются события, связанные со статьями (новостями). Мы будем регистрировать данные о показах статей (views) и кликах по каждой статье (clicks).


По каждому событию мы будем фиксировать несколько атрибутов:
IP-адрес пользователя
город пользователя
referer
UTM-метку из referer
уникальный ID пользователя
 
Подключение к серверу ClickHouse, создание БД и таблицы
Для записи данных о событиях создадим на сервере ClickHouse базу данных articles и внутри — неё таблицу events со следующей структурой:


event_date  Date
event_time  DateTime
event_type  Enum8('VIEWS' = 1, 'CLICKS' = 2)
site_id   Int32
aricle_id   Int32
ip          String
city    String
user_uuid   String
referer    String
utm    String


Сначала рассмотрим создание базы данных и таблицы с помощью нашего графического клиента. Подключаемся через графический клиент к серверу ClickHouse и выполняем запрос на создание новой базы данных и новой таблицы:  


CREATE DATABASE articles
;;
CREATE TABLE articles.events 
(event_date  Date,
event_time  DateTime,
event_type  Enum8('VIEWS' = 1, 'CLICKS' = 2),
site_id   Int32,
aricle_id   Int32,
ip          String,
city    String,
user_uuid   String,
referer    String,
utm    String
) engine=MergeTree(event_date, (site_id, event_date,aricle_id), 8192)
;;


Поясним некоторые параметры этого запроса:
MergeTree — это движок таблицы. Также существуют Log, CollapsingMergeTree, SummingMergeTree, ReplacingMergeTree и другие. 
Первый параметр event_date указывает на имя столбца типа Date, содержащего дату.
(site_id, event_date, aricle_id) — кортеж, определяющий первичный ключ таблицы ( индекс ).


В большинстве запросов на чтение планируется указывать, по какому сайту нам нужны данные, поэтому первым в индексе используется site_id.


Теперь попробуем создать подключение к серверу ClickHouse, базу данных и таблицу через наш драйвер PHP. Для этого сначала установим драйвер. 


Можно установить несколькими вариантами через composer в котором стабильные сборки, или через Git ветка mater, мы в prodaction используем git ветку 




composer require smi2/phpclickhouse


или так, используя Git:


git clone https://github.com/smi2/phpClickHouse.git




Если установки через Git, подключаем драйвер очень просто,   через include_once 'phpClickHouse/include.php';


Основное описание всех ф-ций и ChangeLog опубликованно в Github, 


Теперь выполняем запрос на подключение к серверу, создание БД и таблицы:


<?php


// Конфигурация
$config=['host'=>'192.168.1.20','port'=>'8123','username'=>'default','password'=>''];


// Создаем клиента
$client=new \ClickHouseDB\Client($config);


// Проверяем соединение с базой
$client->ping();


// Отправляем запрос на создание 
$client->write('CREATE DATABASE IF NOT EXISTS articles');
$client->write("


CREATE TABLE IF NOT EXISTS articles.events (
    event_date  Date,
    event_time  DateTime,
    event_type  Enum8('VIEWS' = 1, 'CLICKS' = 2),
    site_id   Int32,
    aricle_id   Int32,
    ip          String,
    city    String,
    user_uuid   String,
    referer    String,
    utm    String
    ) 
    engine=MergeTree(event_date, (site_id, event_date,aricle_id), 8192)
");


// Выбираем default базу
$client->database('articles');


// Получаем список таблиц
print_r($client->showTables());


Обращаем внимание, что запросы в драйвере разделены на следующие:
запись 
вставку данных 
чтение
 
Чтение и вставка могут асинхронными, то есть параллельно может выполняться несколько запросов.


Запросы на запись и вставку данных не содержат ответа, выполняется только проверка того, что ответ сервера был положительным. Запросы на чтение ответ содержат, исключением является прямая запись ответа в файл.
Вставка данных, в том числе из CSV-файла
Вставим данные, которые будем использовать для тестирования:


$client->insert('events',
    [
        [date('Y-m-d'),time(), 'CLICKS', 1, 1234, '192.168.1.1', 'Moscow','xcvfdsazxc','',''],
        [date('Y-m-d'),time(), 'CLICKS', 1, 1235, '192.168.1.1', 'Moscow','xcvfdsazxc','http://yandex.ru',''],
        [date('Y-m-d'),time(), 'CLICKS', 1, 1236, '192.168.1.1', 'Moscow','xcvfdsazxc','',''],
        [date('Y-m-d'),time(), 'CLICKS', 1, 1237, '192.168.1.1', 'Moscow','xcvfdsazxc','',''],
    ],
    ['event_date', 'event_time', 'event_type', 'site_id', 'aricle_id', 'ip', 'city','user_uuid','referer','utm']
);


Такой метод вставки подходит только для маленьких таблиц или таблиц справочников, т/к заставляет PHP перегонять массив в строку.  


Получим результат вставки данных:


print_r(
        $client->select('SELECT * FROM events')->rows()
);


Подробнее про чтение данные написано ниже.


Для вставки большего кол-ва строк воспользуемся прямой загрузкой CSV-файла, который будет генерироваться при событии. Для этого будем записывать CSV-файл на сервере, где происходят события, и, для упрощения, отправлять его оттуда сразу в ClickHouse.


Допустим, что у нас есть некий класс UserEvent, который позволяет получить все необходимые данные для вставки, данные проверены на валидность внутри класса:


$row=
[
    'event_date' =>$UserEvent->date,
    'event_time' =>$UserEvent->time, 
    'event_type' =>$UserEvent->type, 
    'site_id' =>$UserEvent->site_id, 
    'aricle_id' =>$UserEvent->aricle_id, 
    'ip' =>$UserEvent->ip, 
    'city' =>$UserEvent->city, 
    'user_uuid' =>$UserEvent->user_uuid, 
    'referer' =>$UserEvent->referer, 
    'utm' =>$UserEvent->utm, 
];


Запись будем производить в файл, ротируемый ежеминутно, следующим способом (допускаем все недостатки — ошибки записи, блокировки, и т. д . —  строка всегда записывается):    


$filename='/tmp/articles.events_version1_'.date("YmdHi").'.csv';
$text=implode("\t",$row);
file_put_contents($filename,$text."\n",FILE_APPEND);


В примере на GitHub, для тестов, сделан эмулятор класса UserEvent и file_put_contents.


Допустим, что у нас накопилось 5—10 таких файлов, и мы хотим их отправить в базу:


$file_data_names=
[
	'/tmp/articles.events_version1_201612121201.csv',
	'/tmp/articles.events_version1_201612121301.csv',
	'/tmp/articles.events_version1_201612121401.csv'	
]
// Включаем сжатие 
$client->enableHttpCompression(true);


$result_insert = $client->insertBatchFiles('events', $file_data_names, 
['event_date', 'event_time', 'event_type', 'site_id', 'aricle_id', 'ip', 'city','user_uuid','referer','utm']


);


// Можем получить время, за которое данные были доставлены 
foreach ($file_data_names as $fileName) {
    echo $fileName . " : " . $result_insert[$fileName]->totalTimeRequest() . "\n";
}


При больших объёмах вставляемых из файлов данных включаем режим сжатия. В этом случае используется потоковое сжатие, без создания временных файлов, что позволяет экономить на сетевых ресурсах сервера, немного увеличивая нагрузку на CPU. Следовательно скорость передачи данных возрастает, и суммарное время, затраченное на обработку одного файла, уменьшается в несколько раз.


В нашем примере для каждой строки мы передаем поле event_date, хотя эта же дата передаётся в поле event_time. Можно сэкономить ресурсы и не передавать каждый раз поля, которые можно вычислить из другого поля  на сервере ClickHouse. Подробнее о значениях по умолчанию см. в документации по ClickHouse.


Поле utm будем заполнять из поля referer, если в нём указан utm_campaign:
через ф-цию extractURLParameter(referer,’utm_campaign’)


Пересоздадим таблицу:


CREATE TABLE articles.events 
(event_date  Date DEFAULT toDate(event_time),
event_time  DateTime,
event_type  Enum8('VIEWS' = 1, 'CLICKS' = 2),
site_id   Int32,
aricle_id   Int32,
ip          String,
city    String,
user_uuid   String,
referer    String,
utm    String DEFAULT extractURLParameter(referer,'utm_campaign')
) engine=MergeTree(event_date, (site_id, event_date,aricle_id), 8192)
;;


Изменим запись:








Убрать под споллер
$client->insert('events',
    [
        [time(), 'CLICKS', 1, 1234, '192.168.1.11', 'Moscow','user_11',''],
        [time(), 'CLICKS', 1, 1235, '192.168.1.11', 'Moscow','user_11','http://yandex.ru?utm_campaign=abc'],
        [time(), 'CLICKS', 1, 1236, '192.168.1.11', 'Moscow','user_11','http://smi2.ru?utm_campaign=abc'],
        [time(), 'CLICKS', 1, 1237, '192.168.1.11', 'Moscow','user_11',''],
        [time(), 'CLICKS', 1, 1237, '192.168.1.13', 'Moscow','user_13',''],
        [time(), 'CLICKS', 1, 1237, '192.168.1.14', 'Moscow','user_14',''],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.11', 'Moscow','user_11',''],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.12', 'Moscow','user_12',''],




        [time(), 'VIEWS' , 1, 1237, '192.168.1.1', 'Rwanda','user_55',  'http://smi2.ru?utm_campaign=abc'],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.1', 'Banaadir','user_54','http://smi2.ru?utm_campaign=abc'],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.1', 'Tobruk','user_32',  'http://smi2.ru?utm_campaign=CM1'],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.1', 'Gisborne','user_12','http://smi2.ru?utm_campaign=CM1'],
        [time(), 'VIEWS' , 1, 1237, '192.168.1.1', 'Moscow','user_43',  'http://smi2.ru?utm_campaign=CM3'],
    ],
    ['event_time', 'event_type', 'site_id', 'aricle_id', 'ip', 'city','user_uuid','referer']
);




Чтение данных
Меньше слов — больше кода!.. Приведём простой пример, как два запроса выполняются параллельно через драйвер:


$state1 = $db->selectAsync('SELECT 1 as ping');
$state2 = $db->selectAsync('SELECT 2 as ping');
// Отправка запросов в CH
$db->executeAsync();
// Результат 
print_r($state1->rows())
print_r($state2->rows())


Или вариант без асинхронности:


$statement = $db->select(''SELECT 33 as ping'); 


Результат запросов —  это объект Statement, которые умеет делать следующее:


// Посчитать количество строк в результирующем наборе 
$statement->count();


// Посчитать, не менее скольких строчек получилось бы, если бы не было LIMIT-а или rows_before_limit_at_least
$statement->countAll();


// Получить первую строку ответа как массив 
$statement->fetchOne();


// Получить тотальные значения, если в запросе SELECT используется WITH TOTALS
print_r($statement->totals());


// Получить все строки в виде массива 
print_r($statement->rows());


// Получить суммарное время, потраченное на соединение с базой и получение ответа, данные из curl
print_r($statement->totalTimeRequest());


// Получить полный ответ curl_info 
print_r($statement->responseInfo());


// Получить информацию о выполнении запроса предоставленные CH  
print_r($result->statistics());


Попробуем прочитать наши данные. Допустим, нам нужно посчитать, сколько уникальных пользователей просмотрело статьи по дням:


SELECT 
event_date,uniqCombined(user_uuid) as count_users 
FROM events 
GROUP BY event_date 
ORDER BY event_date


Сколько пользователей, которые просматривали статьи, совершили клики: 


SELECT 
  user_uuid,
  count() as clicks
FROM 
  articles.events
WHERE
  event_type='CLICKS'
  AND 
  user_uuid IN 
  (
      SELECT user_uuid FROM articles.events WHERE event_type='VIEWS' GROUP BY user_uuid
  )
GROUP BY user_uuid 


Посчитаем ботов, сделав грубую оценку через количество запросов с одного IP и количество во уникальных ID пользователей:


/* показывать в отчёте только IP, по которым было хотя бы 4 уникальных посетителей. */
SELECT ip,uniqCombined(user_uuid) as count_users FROM events 
WHERE event_date=today()
GROUP BY ip
HAVING count_users >= 4


Какие UTM-метки давали большее количество показов:


SELECT utm,count() as views FROM events 
WHERE event_date=today() AND event_type='VIEWS' AND utm<>''
GROUP BY utm
ORDER BY views DESC
Использование внешних данных для обработки запроса
Допустим, что нам нужно посчитать, сколько уникальных пользователей просмотрело за сутки статьи X, где в X перечислено несколько идентификаторов статей. Это можно сделать так: 


WHERE articles_id IN (1,2,3,4,5,6,7,8,9) 


И в данном примере это будет прекрасно работать. Но что делать, если таких идентификаторов тысячи или десятки тысяч? В этом случае можно использовать, функционал CH  внешние данные для обработки запроса.
 
Рассмотрим эту возможность ClickHouse на примере. 
Создадим CSV-файл '/tmp/articles_list.csv', в котором перечислим все нужные для запроса aricle_id, и попросим ClickHouse создать временную таблицу namex, содержащую одну колонку:


$whereIn = new \ClickHouseDB\WhereInFile();
$whereIn->attachFile('/tmp/articles_list.csv', 'namex', ['article_id' => 'Int32'], \ClickHouseDB\WhereInFile::FORMAT_CSV);


Тогда содержимое файла CSV можно использовать на сервере: 


$sql= “НАписать запрос пример”


$result = $db->select($sql, [], $whereIn);


На этом мы, пожалуй, завершим первую часть нашего рассказа о ClickHouse. Если у вас есть замечания или вы нашли ошибки, опечатки — добро пожаловать в мир open-source, будем ждать ваших pull request по этой статье: https://github.com/smi2/phpClickHouse/blob/master/doc/01_article.md


Если вы любите анализ данных и вам интересно поработать с данными и ClickHouse — добро пожаловать к нам в команду ;)
Что дальше
Мы планируем сделать цикл материалов, посвящённых нашему опыту работы с ClickHouse. В планах — следующие темы.


Часть 2:
Подключение к кластеру ClickHouse из PHP 
Отправка запросов в кластер, реализация миграций на PHP
Семплирование данных в ClickHouse 


Часть 3:
Использование словарей из MySQL в ClickHouse
Движки таблиц: CollapsingMergeTree, SummingMergeTree, MaterializedView


Часть 4:
Примеры запросов в ClickHouse на открытых данных СМИ2
Семплирование данных в Clickhouse
Сравнение с InifiniDB


